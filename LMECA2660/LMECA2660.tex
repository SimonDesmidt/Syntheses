\documentclass[12pt, openany]{report}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{amssymb}
\usepackage{multicol}
\usepackage[a4paper,left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm]{geometry}
\usepackage[english]{babel}
\usepackage{libertine}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{float}
\usepackage{enumitem}
\usepackage{pythonhighlight}
\usepackage[]{titletoc}
\usepackage{empheq}
\usepackage{titlesec}
\usepackage{mathpazo}
\usepackage{xfrac}
\usepackage{textcomp}
\usepackage{mathtools}
\usepackage{caption}
\usepackage{tabularray}
\usepackage{subcaption}
\usepackage[bottom]{footmisc}
\usepackage{pdfpages}
\usepackage{tabularx}
\usepackage{amsthm}
\usepackage[skins]{tcolorbox}
\titleformat{\chapter}[display]
  {\normalfont\bfseries}{}{0pt}{\Huge}
\usepackage{hyperref}
\newcommand{\hsp}{\hspace{20pt}}
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}
\renewcommand{\O}{\mathcal{O}}
\theoremstyle{definition}
\newtheorem{thm}{Theorem}[chapter]
\newtheorem{definition}[thm]{Definition}
\newtheorem{lem}[thm]{Lemma}

% environment derived from framed.sty: see leftbar environment definition
\definecolor{formalshade}{rgb}{0.95,0.95,1}
\definecolor{darkblue}{rgb}{0.0, 0.0, 0.55}

\newenvironment{formal}{
  \def\FrameCommand{
    \hspace{1pt}
    {\color{darkblue}\vrule width 2pt}
    {\color{formalshade}\vrule width 4pt}
    \colorbox{formalshade}
  }
  \MakeFramed{\advance\hsize-\width\FrameRestore}
  \noindent\hspace{-4.55pt}% disable indenting first paragraph
  \begin{adjustwidth}{}{7pt}
  \vspace{2pt}\vspace{2pt}
}
{
  \vspace{2pt}\end{adjustwidth}\endMakeFramed
}

% allows multiple places to referrence the same footnote by using \footnote{\label{x}...} and \footnoteref{x}
\makeatletter
\newcommand\footnoteref[1]{\protected@xdef\@thefnmark{\ref{#1}}\@footnotemark}
\makeatother

\hbadness=100000
\begin{document}
\begin{titlepage}
	\begin{sffamily}
	\begin{center}
		\includegraphics[scale=0.3]{img/page_de_garde.jpg} \\[1cm]
		\HRule \\[0.4cm]
		{ \huge \bfseries LMECA2660 - Numerical Methods in Fluid Mechanics \\[0.4cm] }
	
		\HRule \\[1.5cm]
		\textsc{\LARGE Alexandre Or\'ekhoff \\ \LARGE Simon Desmidt}\\[3cm]
		{This summary may not be up-to-date, the newer version is available at this address: \hyperlink{https://github.com/SimonDesmidt/Syntheses}{https://github.com/SimonDesmidt/Syntheses}}
        \vfill
		\vspace{2cm}
		{\large Academic year 2025-2026 - Q2}
		\vspace{0.4cm}
		 
		\includegraphics[width=0.15\textwidth]{img/epl.png}
		
		UCLouvain\\
	
	\end{center}
	\end{sffamily}
\end{titlepage}

\setcounter{tocdepth}{1}
\tableofcontents
\chapter{Introduction - Finite differences with uniform grid}
\section{Classical finite differences}
Let us define a function $u(\cdot)$ that depends on a variable $x$. Suppose that in the dimension $x$, we discretize the function uniformly with a step $h$ and the values at the nodes are written $u_i$. Then, by a Taylor development series,
\begin{equation}
	\begin{cases}
		u_{i+1} = u_i + h\left(\frac{\partial u}{\partial x}\right)_i + \frac{h^2}{2!}\left(\frac{\partial^2 u}{\partial x^2}\right)_i + \frac{h^3}{3!}\left(\frac{\partial^3 u}{\partial x^3}\right)_i + \frac{h^4}{4!} \left(\frac{\partial^4 u}{\partial x^4}\right)_i + \dots \\
		u_{i-1} = u_i - h\left(\frac{\partial u}{\partial x}\right)_i + \frac{h^2}{2!}\left(\frac{\partial^2 u}{\partial x^2}\right)_i - \frac{h^3}{3!}\left(\frac{\partial^3 u}{\partial x^3}\right)_i + \frac{h^4}{4!} \left(\frac{\partial^4 u}{\partial x^4}\right)_i - \dots \\
	\end{cases}
\end{equation}
This gives three possible finite-difference approximations:
\begin{equation}
	\begin{aligned}
		\left(\frac{\partial u}{\partial x}\right)_i = \frac{u_{i+1}-u_i}{h} + \mathcal{O}(h) & \qquad \text{(Forward differences)}\\
		\left(\frac{\partial u}{\partial x}\right)_i = \frac{u_{i}-u_{i-1}}{h} + \mathcal{O}(h) & \qquad \text{(Backward differences)}\\
		\left(\frac{\partial u}{\partial x}\right)_i = \frac{u_{i+1}-u_{i-1}}{2h} + \mathcal{O}(h^2) & \qquad \text{(Centered differences)}\\
	\end{aligned}
\end{equation}
This also gives, for the second order, 
\begin{equation}
	\left(\frac{\partial^2 u}{\partial x^2}\right)_i = \frac{u_{i+1}-2u_i+u_{i-1}}{h^2} - \frac{h^2}{12} \left(\frac{\partial^4u}{\partial x^4}\right)_i + \dots 
\end{equation}
\begin{itemize}
	\item [$\to$] Note: in general, discentered differences are only used for stability reasons.
\end{itemize}
\section{Richardson extrapolation}
Richardson extrapolation combines centered finite differences at different scales to get a better error:
\begin{equation}
	\begin{aligned}
		\textcolor{red}{\frac{4}{3}\Big [}&\left(\frac{\partial u}{\partial x}\right)_i = \frac{u_{i+1}-u_{i-1}}{2h} - \frac{h^2}{6}\left(\frac{\partial^3 u }{\partial x^3}\right)_i - \frac{h^4}{120}\left(\frac{\partial^5 u}{\partial x^5}\right)_i - \dots\textcolor{red}{\Big]}\\
		\textcolor{red}{\frac{-1}{3}\Big [}&\left(\frac{\partial u}{\partial x}\right)_i = \frac{u_{i+2}-u_{i-2}}{2(2h)} - \frac{(2h)^2}{6}\left(\frac{\partial^3 u }{\partial x^3}\right)_i - \frac{(2h)^4}{120}\left(\frac{\partial^5 u}{\partial x^5}\right)_i - \dots\textcolor{red}{\Big]}\\
		\Longrightarrow &\left(\frac{\partial u}{\partial x}\right)_i = \frac{8(u_{i+1}-u_{i-1})-(u_{i+2}-u_{i-2})}{12h} + \frac{h^4}{30}\left(\frac{\partial^5 u}{\partial x^5}\right)_i - \dots
	\end{aligned}
\end{equation}
With this method, the truncation error is of order $\mathcal{O}(h^4)$. In the same way, for second order,
\begin{equation}
	\left(\frac{\partial^2u}{\partial x^2}\right)_i = \frac{4}{3}\frac{u_{i+1}-2u_i+u_{i-1}}{h^2} - \frac{1}{3}\frac{u_{i+2}-2u_i+u_{i-2}}{(2h)^2} + \mathcal{O}(h^4)
\end{equation}
\section{Operators}
Let us define the following operators:
\begin{itemize}
	\item Forward difference: $\Delta u_i = u_{i+1} - u_i$;
	\item Backward difference: $\nabla u_i = u_{i}-u_{i-1}$;
	\item Centered difference: $\delta u_i = u_{i+1/2}-u_{i-1/2}$;
	\item Mean: $\mu u_i = \frac{1}{2}(u_{i+1/2}+u_{i-1/2})$;
	\item [$\to$] Note: $u_{i+1/2}$ and $u_{i-1/2}$ are not computable because they are not grid values, but can be used for derivations of other formulae.
	\item Identity operator: $Iu_i = u_i$;
	\item Forward operator: $Eu_i = u_{i+1}$;
	\item Backward operator: $E^{-1}u_i = u_{i-1}$;
	\item [$\to$] Note: $E^{-1} E = I$.
\end{itemize}
Those operators have the following properties:
\begin{itemize}
	\item $\mu \delta = \frac{1}{2}(E-E^{-1})$;
	\item $\mu^2 = I+\delta^2/4$;
\end{itemize}
The forward operator can be re-expressed using a Taylor development series:
\begin{equation}
	\begin{aligned}
		Eu_i &= u_{i+1} = u_i + h\frac{\partial }{\partial x} u_i + \frac{h^2}{2!} \frac{\partial^2}{\partial x^2} u_i + \frac{h^3}{3!} \frac{\partial^3}{\partial x^3}_i + \dots \\
		&= \left(I+hD+\frac{(hD)^2}{2!} + \frac{(hD)^3}{3!} + \dots\right)u_i = \exp(hD)u_i
	\end{aligned}
\end{equation}
From this, using a second Taylor development series,
\begin{equation}
	hD = \log(I+\Delta) = \Delta - \frac{\Delta^2}{2} + \frac{\Delta^3}{3} - \frac{\Delta^4}{4} + \dots 
\end{equation}
And, in the same way, 
\begin{equation}
	hD = -\log (I-\nabla) = \nabla + \frac{\nabla^2}{2} + \frac{\nabla^3}{3} + \frac{\nabla^4}{4} + \dots 
\end{equation}
We can do the same for another operator:
\begin{equation}
	\mu \delta = \frac{1}{2}(E-E^{-1}) = \frac{1}{2}\left(\exp(hD)-\exp(-hD)\right) = \sinh(hD)
\end{equation}
and we can use the Taylor series for $arc\sinh(x)$ but it is not very useful. By the property that $\mu^2 = I+\delta^2/4$, we get another form:
\begin{equation}
	hD = \mu\delta \left(I-\frac{1}{6}\delta^2 + \frac{1}{30}\delta^4 - \frac{140}{\delta^6} + \dots\right)
\end{equation}
If we keep only the first order term, we find the centered-difference scheme, and the terms up to second order give the Richardson extrapolation. 
\begin{itemize}
	\item [$\to$] Note: in any scheme, using more information (more values, e.g. $u_{i+2}, u_{i+3}, \dots$) gives a more accurate solution and the order of the truncation error increases (e.g. to $\mathcal{O}(h^3)$). 
\end{itemize}
\section{2D Laplacian}
For finite differences in 2D, we can define several types of stencils. For a second-order error, there is the cross operator, which is simply the sum of classical centered finite differences on both axes, and the box operator. This operator is a linear combination of the cross operator using the medians of the square, and the one that uses the diagonals of the square (see \ref{fig:cross-op}).
\begin{figure}[H]
	\centering
	\includegraphics[width=.7\textwidth]{img/cross_op.png}
	\caption{Cross operator and box operator.}
	\label{fig:cross-op}
\end{figure}
The box operator expresses the following quantity:
\begin{equation}
	h^2 \nabla^2 \left(u+\frac{h^2}{12}\nabla^2 u  + \dots \right) = h^2 \left(\nabla^2 u + \frac{h^2}{12}\nabla^2 (\nabla^2 u)\right)
\end{equation}
Those stencils can be generalized to higher orders using more points (bigger cross and bigger square). 
\begin{itemize}
	\item [$\to$] Note: the coefficients are found using the constraint that the truncation error is independent of orientation of the stencil. 
\end{itemize}
\chapter{Space integration}
\section{Convection equation}
The convection equation is 
\begin{equation}
	\frac{\partial u}{\partial t} + c \frac{\partial u}{\partial x}=0
\end{equation}
The analytic solution of this equation on an infinite domain, for a speed $c$ constant, is 
\begin{equation}
	u(x,t) = A(t)e^{ikx} = A(0)e^{ik(x-ct)}
\end{equation}
On a periodic domain of length $L$, the solution is 
\begin{equation}
	\begin{aligned}
		u(x,t) = \sum_{k=-\infty}^\infty A_k(t)e^{ikx}\qquad k=\frac{2\pi}{L}p \qquad p\in \Z\\
		\Longrightarrow u(x,t) = \sum_{p=-\infty}^\infty A_p(t) e^{i\frac{2\pi x}{L}}
	\end{aligned}
\end{equation}
where the coefficients verify the condition $A_k = A_{-k}^*$ for all $k$, since the solution must be real. In the exact solution, all the modes have the same speed $c$. 
\subsection{Explicit schemes}
However, all modes do not have the same velocity when we use explicit finite differences. Let us show it in the case of an infinite domain (same thing happens for a periodic domain, adding the sum on $p$):\\
Let $u_i(t) = A(t) e^{j kx_i}$. Then,
\begin{equation}
	\begin{aligned}
		\left. \frac{\partial u}{\partial x}\right|_i = A j k^* \exp(jkx_i) \Longrightarrow \frac{dA}{dt} + j k^* c A = 0 \\ \Longrightarrow u_i(t) = A(0) e^{j(kx_i - k^* ct)} = A(0) e^{ik\left(x_i - \frac{k^*h}{kh}ct\right)}
	\end{aligned}
\end{equation}
we call $k^*$ the modified wave number. It is different from $k$ because all the modes do not move at the same speed. For example, for the E2 stencil, its expression is derived in the following way:
\begin{equation}
	\begin{aligned}
		\left. \frac{\partial u}{\partial x}\right|_i = \frac{u_{i+1}-u_i}{2h} = \frac{A}{h} \frac{1}{2}(e^{jkh}-e^{-jkh})e^{jkx_i} = \frac{A}{h} j \sin(kh)e^{ikx_i} = A j k^* e^{jkx_i}\\
		\Longrightarrow k^*h = \sin(kh)
	\end{aligned}
\end{equation}
This is a \textbf{phase} error, as the modes do not \textbf{move} with the right \textbf{velocity}.\\
By a Taylor development, 
\begin{equation}
	\frac{k^*h}{kh} = 1 - \frac{(kh)^2}{6} + \mathcal{O}((kh)^4)
\end{equation}
and although $k$ is not constant for all modes, the error of the stencil is still of the same order: $\mathcal{O}((kh)^2)$. Moreover, the speed of the modes is $c^* = \frac{k^*h}{kh}c$.
\begin{figure}[H]
	\centering 
	\includegraphics[width=.5\textwidth]{img/convection-kmod.png}
	\caption{Evolution of the exact wave number and the modified wave number.}
	\label{fig:kh/kh}
\end{figure}
As the error increases when $k$ increases, it is important to use a very refined grid so that all points whose amplitude is non negligible have $k^* h \approx kh$. 
\subsection{Implicit schemes}
The general scheme of implicit finite differences is the following:
\begin{equation}\label{eq:I-order1}
	\begin{aligned}	
		\frac{\partial u}{\partial x}_i + \alpha\frac{1}{2}\left(\left.\frac{\partial u}{\partial x}\right|_{i+1}+\left.\frac{\partial u}{\partial x}\right|_{i-1}\right) + \beta \frac{1}{2}\left(\left.\frac{\partial u}{\partial x}\right|_{i+2} + \left.\frac{\partial u}{\partial x}\right|_{i-2}\right) \\
		= a \frac{u_{i+1}-u_{i-1}}{2h} + b\frac{u_{i+2}+u_{i-2}}{4h} + c \frac{u_{i+3}-u_{i-3}}{6h}
	\end{aligned}
\end{equation}
Usually, we use $\beta=c=0$ to keep only the nearest grid points to $i$. Those schemes are called compact. \\
We can use $\left.\frac{\partial u}{\partial x}\right|_{i} = A j k^* e^{jkx_i}$ and $\frac{u_{i+1}-u_{i-1}}{2h} = \sin(kh)$ to show that 
\begin{equation}
	k^*h = \frac{a\sin(kh) + \frac{b}{2}\sin(2kh) + \frac{c}{3}\sin(3kh)}{1+\alpha \cos(kh)+\beta \cos(2kh)}
\end{equation}
We can do a Taylor development of this quantity to get different schemes:
\begin{equation}
	\begin{aligned}
		\text{Taylor of order 1:}\qquad  1+\alpha+\beta =& a+b+c \Longrightarrow \text{Error of order 2}\\
		\text{Taylor of order 2:}\qquad  3(\alpha+2^2\beta) =& a+2^2b+3^2c \Longrightarrow \text{Error of order 4}\\
		\text{Taylor of order 3:}\qquad  5(\alpha+2^4\beta) =& a+2^4b+3^4c \Longrightarrow \text{Error of order 6}\\
		\text{Taylor of order 4:}\qquad  7(\alpha+2^6\beta) =& a+2^6b+3^6c \Longrightarrow \text{Error of order 8}\\
		\text{Taylor of order 5:}\qquad  9(\alpha+2^8\beta) =& a+2^8b+3^8c \Longrightarrow \text{Error of order 10}\\
	\end{aligned}
\end{equation}
For example, in the case where $\beta= 0$ and $\alpha \neq 0$, the system is tridiagonal and the solver has a time complexity of $\mathcal{O}(N)$. For $\beta=0$ and $\alpha=0$, we find the explicit scheme. 
\begin{itemize}
	\item [$\to$] Note: The I4o scheme is the scheme with the smallest constant before the $(kh)^4$ using all parameters. For this one, the sign of that constant is positive, meaning that it goes above the correct velocity. This behaviour is not present on the other scheme. 
\end{itemize}
\section{Diffusion equation}
The diffusion equation is 
\begin{equation}\label{eq:diffusion}
	\frac{\partial u}{\partial t} = \alpha \frac{\partial^2 u}{\partial x^2}
\end{equation}
This equation is not reversible because it represents a loss of information: the high-wave-number terms decay fast and have no impact after a small time.\\
The exact solution is $u(x,t) = A_k(t)e^{jkx}$ with $A_k(t) = A_k(0)e^{\alpha k^2 t}$. 
\subsection{Explicit schemes}
The explicit finite differences scheme is 
\begin{equation}
	\left.\frac{\partial^2 u}{\partial x^2}\right|_i = a\frac{u_{i+1}-2u_i+u_{i-1}}{h^2} + b\frac{u_{i+2}-2u_i+u_{i-2}}{4h^2} + c\frac{u_{i+3}-2u_i+u_{i-3}}{9h^2}
\end{equation}
Let $u_i(t) = A(t) e^{jkx_i}$. Then, 
\begin{equation}
	\frac{dA}{dt} = -\alpha (k^2)^* A \Longrightarrow A(t) = A(0)e^{-\alpha (k^2)^* t} e^{jkx_i} \Longrightarrow u_i(t) = A(0)e^{-\alpha k^2 \left(\frac{\left(k^2\right)^*h^2}{k^2 h^2}\right)}e^{jkx_i}
\end{equation}
This is a \textbf{amplitude} error, as the mode do not decay with the proper \textbf{rate}. \\
For example, for the explicit scheme of order 2 ($a=1$, $b=c=0$), the modified $k^2$ is given by
\begin{equation}
	(k^1)^*h^2 = 4\sin^2 \left(\frac{kh}{2}\right) \Longleftrightarrow \frac{(k^2)^* h^2}{k^2 h^2} = \frac{\sin^2 \left(\frac{kh}{2}\right)}{\left(\frac{kh}{2}\right)^2}
\end{equation}
\subsection{Implicit schemes}
The general form of the implicit scheme follows the same reasoning as for \eqref{eq:I-order1}.
\begin{equation}
	\begin{aligned}
		\left.\frac{\partial^2 u}{\partial x^2}\right|_i + \alpha \frac{1}{2}\left(\left.\frac{\partial^2 u}{\partial x^2}\right|_{i+1} + \left.\frac{\partial^2 u}{\partial x^2}\right|_{i-1}\right) + \beta \frac{1}{2}\left(\left.\frac{\partial^2 u}{\partial x^2}\right|_{i+2} + \left.\frac{\partial^2 u}{\partial x^2}\right|_{i-2}\right) \\
		= a \frac{u_{i+1}-2u_i+u_{i-1}}{h^2} + b \frac{u_{i+2}-2u_i+u_{i-2}}{4h^2} + c \frac{u_{i+3}-2u_i+u_{i-3}}{9h^2}
	\end{aligned}
\end{equation}
By using $\left.\frac{\partial^2 u}{\partial x^2}\right|_i = -A(t) (k^2)^*e^{jkx_i}$, we can show that 
\begin{equation}
	(k^2)^*h^2 = \frac{4\left[a\sin^2\left(\frac{kh}{2}\right) + \frac{b}{4}\sin^2 \left(\frac{2kh}{2}\right) + \frac{c}{9}\sin^2 \left(\frac{3kh}{2}\right)\right]}{1+\alpha \cos(kh)+\beta\cos(2kh)}
\end{equation}
As previously, we can do the Taylor development series of this expression to get different schemes:
\begin{equation}
	\begin{aligned}
		\text{Taylor of order 1:}\qquad  1+\alpha+\beta =& a+b+c \Longrightarrow \text{Error of order 2}\\
		\text{Taylor of order 2:}\qquad  2\cdot3(\alpha+2^2\beta) =& a+2^2b+2^2c \Longrightarrow \text{Error of order 4}\\
		\text{Taylor of order 3:}\qquad  3\cdot5(\alpha+2^4\beta) =& a+2^4b+2^4c \Longrightarrow \text{Error of order 6}\\
		\text{Taylor of order 4:}\qquad  4\cdot7(\alpha+2^6\beta) =& a+2^6b+2^6c \Longrightarrow \text{Error of order 8}\\
		\text{Taylor of order 5:}\qquad  5\cdot9(\alpha+2^8\beta) =& a+2^8b+2^8c \Longrightarrow \text{Error of order 10}\\
	\end{aligned}
\end{equation}
\begin{figure}[H]
	\centering 
	\includegraphics[width=.5\textwidth]{img/diffusion-kmod.png}
	\caption{Evolution of the modified $k^2$ with $k^2$.}
	\label{fig:diffusion-kmod}
\end{figure}
\section{One-sided finite differences}
Let us consider the backward differences for the convection equation:
\begin{equation}\label{eq:upwind}
	\frac{d}{dt} u_i = - c \frac{u_i-u_{i-1}}{h}\Longrightarrow \frac{d}{dt} A_k = -\frac{c}{h} (1-e^{jkh})
\end{equation}
Then, $\lambda_k = -\frac{c}{h} (1-e^{-jkh})$ is no longer purely imaginary. Its real part gives an amplitude error (numerical diffusion) and its imaginary part gives a (numerical) dispersion error. 
\begin{itemize}
	\item [$\to$] Note: for $c<0$, we need to use forward differences instead because otherwise the real part of $\lambda_k$ becomes positive and thus unstable. 
\end{itemize}
Let us compute the term of numerical diffusion:
\begin{equation}
	\frac{d}{dt}u_i = -c\frac{u_i-u_{i-1}}{h} = -c \frac{u_{i+1}-u_{i-1}}{2h} + c \frac{u_{i+1}-2u_i+u_{i-1}}{2h} = -c \frac{u_{i+1}-u_{i-1}}{2h} + \frac{ch}{2}\frac{u_{i+1}-2u_i+u_{i-1}}{h^2}
\end{equation}
The modified equation becomes
\begin{equation}
	\frac{\partial u}{\partial t} + c\frac{\partial u}{\partial x} = \frac{ch}{2} \frac{\partial^2 u}{\partial x^2} + \dots 
\end{equation}
and so the diffusivity parameter is thus $\epsilon = \frac{ch}{2}$. \\
For this scheme, from \eqref{eq:upwind}, $\lambda_k \Delta t = -\frac{c\Delta t}{h} \left((1-\cos(kh)) + i\sin(kh)\right)$ and the region of stability of the method is a circle centered in $(-1,0)$ in the complex plane of $\lambda_k \Delta t$. 
\subsection{One-sided finite differences of higher order}
This type of scheme of higher order would give for example 
\begin{equation}
	\begin{aligned}
		\frac{d}{dt} u_i &= \frac{3u_i -4u_{i-1}+u_{i-2}}{2h}\\
		& = \frac{11u_i-18u_{i-1}+9u_{i-2}-2u_{i-3}}{6h}
	\end{aligned}
\end{equation}
and all those expressions give different stability regions. The general form for the spatial derivative is 
\begin{equation}
	\left.\frac{\partial u}{\partial x}\right|_i = a_1 \frac{u_i-u_{i-1}}{h} + a_2 \frac{u_i-u_{i-2}}{2h} + a_3 \frac{u_i-u_{i-3}}{3h}
\end{equation}
\begin{figure}[H]
	\centering 
	\includegraphics[width=.6\textwidth]{img/decentered_convection.png}
	\caption{Stability regions for one-sided schemes.}
	\label{fig:decentered-convection}
\end{figure}
This means that if our system has a high eigenvalue $\lambda$, we need to decrease the time step to have convergence properties. This means that those one-sided schemes are not much helpful, because they are very costly. Moreover, at order 3, we can see low wave numbers with positive real part, meaning that they blow up (positive exponent in the exponential). 
\section{Convection-diffusion equation}
The convection-diffusion equation is 
\begin{equation}
	\frac{\partial u}{\partial t} + c \frac{\partial u}{\partial x} = \epsilon \frac{\partial^2 u}{\partial x^2}
\end{equation}
\begin{itemize}
	\item [$\to$] Note: numerical diffusion can appear and pollute the physical diffusion. This is not a problem if we have $\epsilon_{num} \ll \epsilon_{phys}$. 
\end{itemize}
\subsection{Centered finite differences}
The scheme here is 
\begin{equation}
	\frac{d}{dt}u_i = -c \frac{u_{i+1}-u_{i-1}}{2h} + \epsilon \frac{u_{i+1}-2u_i+u_{i-1}}{h^2}
\end{equation}
This gives 
\begin{equation}
	\lambda_k = -\frac{2\epsilon}{h^2} (1-\cos(kh)) - j \frac{c}{h}\sin(kh)
\end{equation}
This expression in the complex plane of $\lambda_k\Delta t$ is an ellipse with vertical axis $b=\beta$ and horizontal axis $a=2r$, $\beta=c\Delta t/h$ being the CFL number, and $r=\epsilon \Delta t/h^2$ being the Fourier number. We also define the mesh Peclet number $R= |c|h/\epsilon$, giving the identity $\beta = rR$. \\
This scheme, using a Euler scheme for integration, is stable if the ellipse is fully contained in the circle centered in $(-1,0)$. 
\begin{itemize}
	\item If $b\le a$, the scheme is stable if $a\le 1$, or equivalently, if $R\le 2$, the scheme is stable if $r\le 1/2$;
	\item If $b>a$, the scheme is stable if the largest radius of curvature of the ellipse is $\le 1$\footnote{This value is the radius of curvature of the circle.}, i.e. $b^2/a \le 1 \Longleftrightarrow c^2\Delta t/\epsilon \le 2$, or equivalently, if $R>2$, this scheme is stable for $r\le 2/R^2$. 
\end{itemize}
\begin{figure}[H]
	\centering 
	\includegraphics[width=.5\textwidth]{img/ellipse.png}
	\caption{Stability region for the parameters of the convection-diffusion equation.}
	\label{fig:ellipse}
\end{figure}
If using backward finite differences, i.e. $c>0$, the scheme is 
\begin{equation}
	\frac{d}{dt} u_i = -c\frac{u_i-u_{i-1}}{h} + \epsilon \frac{u_{i+1}-2u_i+u_{i-1}}{h^2} = -c \frac{u_{i+1}-u_{i-1}}{2h} + \left(\epsilon + \frac{ch}{2}\right) \frac{u_{i+1}-2u_i+u_{i-1}}{h^2}
\end{equation}
Then, 
\begin{equation}
	\lambda_k = -\left(\frac{c}{h} +\frac{2\epsilon}{h^2}\right)(1-\cos(kh)) - j\frac{c}{h} \sin(kh)
\end{equation}
This is also an ellipse, with axes $a = \beta + 2r$ and $b = \beta$. Here, $b\le a$ becaue $r>0$ always, and thus 
\begin{equation}
	r \le \frac{1}{1+R}
\end{equation}
\begin{figure}[H]
	\centering 
	\includegraphics[width=.6\textwidth]{img/conv_diff_stability.png}
	\caption{Stability region of the convection-diffusion equation.}
	\label{fig:conv-diff}
\end{figure}
\section{Convection equation in 2D}
The convection equation in 2D has two different velocity values:
\begin{equation}
	\frac{\partial u}{\partial t} + u_0 \frac{\partial u}{\partial x} + v_0 \frac{\partial u}{\partial y} = 0
\end{equation}
We consider here a periodic problem to be able to do a modal analysis. 
The E2 scheme gives 
\begin{equation}
	\frac{du_{ij}(t)}{dt} = -\left(u_0\frac{u_{i+1,j}-u_{i-1,j}}{2\Delta x} + v_0 \frac{u_{i,j+1}-u_{i,j-1}}{2\Delta y}\right)
\end{equation}
Which gives a system of ODEs for the $u_{i,j}(t)$. \\
In the continuous problem, the solution is 
\begin{equation}
	u(x,y,t) = \sum_{k,\ell} A_{k\ell}(t) e^{j(kx+\ell y)}
\end{equation}
Our ODE gives 
\begin{equation}
	A_{k\ell }(t) = A_{k\ell}(0) e^{-j(u_0k+v_0\ell)t}
\end{equation}
For the discrete problem (in space but continuous time), the ODE for $A_{k\ell}$ is 
\begin{equation}
	\frac{dA_{k\ell}}{dt} = -j\left(\frac{u_0}{\Delta x} \sin(k\Delta x) + \frac{v_0}{\Delta y}\sin(l\Delta y)\right) A_{k\ell}
\end{equation}
and so the eigenvalues $\lambda_{k\ell}$ are purely imaginary, with $\lambda_{k\ell} = \lambda_k + \lambda_\ell$. We can also define the global CFL number 
\begin{equation}
	\beta = \beta_x + \beta_y = \frac{|u_0|\Delta t}{\Delta x} + \frac{|v_0|\Delta t}{\Delta y}
\end{equation}
and 
\begin{equation}
	|\lambda_{k\ell}|_{\max} \Delta t = \beta 
\end{equation}
\section{Convection-diffusion equation in 2D}
\begin{equation}
	\frac{\partial u}{\partial t} + u_0 \frac{\partial u}{\partial x} + v_0 \frac{\partial u}{\partial y} = \epsilon \left(\frac{\partial^2u}{\partial x^2} + \frac{\partial^2 u}{\partial y^2}\right) 
\end{equation}
We can compute the eigenvalues by using a scheme, e.g. E2, to get 
\begin{equation}
	\frac{dA_{k\ell}}{dt} = \lambda_{k\ell} A_{k\ell}
\end{equation}
The parameters of the scheme are 
\begin{equation}
	\begin{cases}
		r_x = \frac{\epsilon \Delta t}{(\Delta x)^2} \qquad R_x = \frac{|u_0| \Delta x}{\epsilon} \Longrightarrow \beta_x = r_xR_x\\
		r_y = \frac{\epsilon \Delta t}{(\Delta y)^2} \qquad R_y = \frac{|v_0| \Delta y}{\epsilon} \Longrightarrow \beta_y = r_yR_y\\
	\end{cases}
\end{equation}
In the case $\Delta x=  Delta y = h$, $r_x=r_y=r=\epsilon \Delta t/ h^2$ and 
\begin{equation}
	\begin{cases}
		\beta_x = \frac{|u_0| \Delta t}{h}\\
		\beta_Y = \frac{|v_0| \Delta t}{h}
	\end{cases} \Longrightarrow \begin{cases}
		\beta = \beta_x + \beta_y = \frac{(|u_0|+|v_0|)\Delta t}{h}\\
		R = R_x+R_y = \frac{(|u_0| + |v_0|)h}{\epsilon}
	\end{cases}
\end{equation}
\chapter{Numerical time-integration schemes for ODEs}
The general formulation of first order ODEs is 
\begin{equation}
	\frac{du}{dt} = f(u,t)
\end{equation}
Until now, we have only had a simple system with $f(u,t) = \lambda u$. \\
We can do a Taylor development of $f(\cdot)$ to analyze the local behaviour of the system:
\begin{equation}
	\frac{du}{dt} = f(u,t) = \underbrace{f(u_0,t_0)}_{\coloneqq\beta} + (u-u_0)\underbrace{\frac{\partial f}{\partial u}}_{=\eqqcolon \lambda} + (t-t_0) \underbrace{\frac{\partial f}{\partial t}(u_0,t_0)}_{\eqqcolon \gamma} + \dots 
\end{equation}
and defining $u' = u-u_0$ and $t'=t-t_0$. The solution of this is 
\begin{equation}
	u'(t) = u_p' + u_g' = -\frac{1}{\lambda}\left(\gamma t' + \left(\frac{\gamma}{\lambda}+ \beta\right)\right) + A e^{\lambda t'} = \frac{1}{\lambda}\left[\left(\frac{\gamma}{\lambda} + \beta\right)\left(e^{\lambda t'} -1\right) - \gamma t'\right]
\end{equation}
The stability of the scheme used to integrate that ODE is governed by the homogeneous part of the equation, as it is the only one that can blow up (exponential term). \\

For our special case $\frac{du}{dt} = \lambda u$, the solution is $u(t) = u(0)e^{\lambda t}$. As we use a discretized space, let $t=t^n = n\Delta t$. Then, $u^n = u(t^n) = (e^{\lambda \Delta t})^n u^0 = (\rho_e)^nu^0$, where we call $\rho_e$ the amplification factor of the exact solution. The ODE is (physically) stable if $|\rho_e| \le 1$. In the $\lambda \Delta t$ complex plane, it represents the left half-plane. 
\section{Explicit Euler scheme}
\begin{equation}
	\frac{u^{n+1}-u^n}{\Delta t} = \lambda u^n
\end{equation}
Then, 
\begin{equation}
	u^{n+1} = (1+\lambda \Delta t)u^n = \rho u^n \Longrightarrow u^n = (\rho)^n u^0
\end{equation}
The scheme is stable if 
\begin{equation}
	|\rho|^2 = (1+\lambda_r \Delta t)^2 + (\lambda_i\Delta t)^2 \le 1
\end{equation}
This is a circle centered in $(-1,0)$. \\

At each time stpe, the Euler scheme produces an $\mathcal{O}((\Delta t)^2)$ error. To arrive at $t=T$, it takes $N=T/\Delta t$ time steps. The error at $t=T$ is thus $\mathcal{O}((\Delta t)^2/\Delta t) = \mathcal{O}(\Delta t)$. The Euler scheme if a first-order scheme.
\begin{itemize}
	\item [$\to$] Note: always check the order of a scheme using a fixed time interval, and not a single time step, as we want a global estimation. 
\end{itemize}
\section{Implicit Euler scheme}
\begin{equation}
	\frac{u^{n+1}-u^n}{\Delta t} = \lambda u^{n+1}
\end{equation}
Then, 
\begin{equation}
	u^{n+1} = \frac{1}{1-\lambda \Delta t} u^n = \rho u^n 
\end{equation}
This scheme is unconditionnally stable, as it is stable for all problems with $\lambda_r \le 0$ and we do not consider the problems that are not physically stable. 
\section{Trapezoid rule}
\begin{equation}
	\frac{u^{n+1}-u^n }{\Delta t} = \lambda \frac{u^{n+1}-u^n}{2}
\end{equation}
Then, 
\begin{equation}
	u^{n+1} = \frac{1+\frac{\lambda \Delta t}{2}}{1-\frac{\lambda \Delta t}{2}} u^n = \rho u^n
\end{equation}
This scheme is also unconditionnally stable for physically stable problems. Moreover, it is of second order, because it is centered around $t^{n+1/2}$. 
\section{Explicit Runge-Kutta schemes}
We will work here on the integration of ODEs of the form 
\begin{equation}
	\frac{du}{dt} = f(u,t)
\end{equation}
The notation is $f^n = f(u^n,t^n)$ for the value of the function at the $n$-th time step. \\ 
The general form of a Runge-Kutta scheme of order $m$ is the following:
\begin{equation}
	u^{n+1} = u^n + \sum_{i=1}^m \gamma_ik_i \qquad \text{ s.t. }\qquad \begin{cases}
		k_1 = \Delta t f(u^n, t^n)\\
		k_i = \Delta t f(u^n + \sum_{j=1}^{i-1}\beta_{ji} k_j, t^n + \sum_{j=1}^{i-1} \alpha_j \Delta t) \qquad \forall i \ge 2
	\end{cases}
\end{equation}
\subsection{RK2}
The formulation of order two is 
\begin{equation}
	u^{n+1} = u^n + \gamma_1 k_1 + \gamma_2 k_2 \qquad \text{ s.t. }\qquad \begin{cases}
		k_1 = \Delta t f(u^n, t^n)\\
		k_2 = \Delta t f(u^n + \beta k_1, t^n +\alpha \Delta t)
	\end{cases}
\end{equation}
The explicit Runge-Kutta schemes work with Taylor series:
\begin{equation}
	u^{n+1} = u^n + \Delta t \left(\frac{du}{dt}\right)^n + \frac{(\Delta t)^2}{2} \left(\frac{d^2u}{dt^2}\right)^n + \O((\Delta t)^3)
\end{equation}
and
\begin{equation}
	\begin{aligned}
		k_2 &= \Delta t \left[f^n + \beta k_1\left(\frac{\partial f}{\partial u}\right)^n + \alpha \Delta t \left(\frac{\partial f}{\partial t}\right)^n + \dots \right]\\
		\Longrightarrow u^{n+1} &= u^n + \gamma_1 \Delta tf^n + \gamma_2 \Delta t\left[f^n + \beta \Delta tf^n \left(\frac{\partial f}{\partial u}\right)^n + \alpha \Delta t\left(\frac{\partial f}{\partial t}\right)^n + \dots \right]
	\end{aligned}
\end{equation}
By comparing those developments, we find a system of 3 equations:
\begin{equation}
	\begin{aligned}
		&\gamma_1 + \gamma_2 = 1 \\
		&\gamma_2 \beta = 1/2\\
		&\gamma_2 \alpha = 1/2 
	\end{aligned}
\end{equation}
There remains one degree of freedom, meaning we get a family of schemes. The usual methods are 
\begin{itemize}
	\item RK2 classic: Heun's method
	\begin{equation}
		\begin{aligned}
			\gamma_1 = \gamma_2 = 1/2 \\
			\alpha = \beta = 1\\
		\end{aligned}
	\end{equation}
	\begin{equation}
		\begin{cases}
			k_1 = \Delta t f(u^n,t^n)\\
			k_2 = \Delta t f(u^n + k_1, t^n + \Delta t)\\
		\end{cases} \Longrightarrow u^{n+1} = u^n + \frac{1}{2}k_1 + \frac{1}{2}k_2
	\end{equation}
	\item RK2 classic: midoint method
	\begin{equation}
		\begin{aligned}
			\gamma_1 = 0 \quad \gamma_2 = 1\\
			\alpha = \beta = 1/2
		\end{aligned}
	\end{equation}
	\begin{equation}
		\begin{cases}
			k_1 = \Delta t f(u^n,t^n)\\
			k_2 = \Delta t f(u^n + \frac{1}{2}k_1, t^n + \frac{1}{2}\Delta t)
		\end{cases} \Longrightarrow u^{n+1} = u^n + k_2 
	\end{equation}
\end{itemize}
\subsection{RK3-4}
Runge-Kutta 3 and 4 are to be derived in the same way. They both have two degrees of freedom and thus it is possible to have many different approaches to get the coefficients. The most common way is to do a diagonal scheme, i.e. $k_{j}$ only depends on the value of $k_{j-1}$. This gives the usual RK4 method 
\begin{equation}
	\begin{aligned}
		\begin{cases}
			k_1 = \Delta t f(u^n, t^n)\\
			k_2 = \Delta t f(u^n + \frac{1}{2}k_1, t^n + \frac{1}{2}\Delta t)\\
			k_3 = \Delta t f(u^n + \frac{1}{2}k_2, t^n + \frac{1}{2}\Delta t)\\
			k_4 = \Delta t f(u^n + k_3, t^n + \Delta t)
		\end{cases}\\
		u^{n+1} = u^n + \frac{1}{6}\left(k_1 + 2k_2+2k_3+k_4\right)
	\end{aligned}
\end{equation}
\subsection{Runge Kutta schemes in stability analysis}
The analysis of stability is for the equation 
\begin{equation}
	\frac{du}{dt} = \lambda u
\end{equation}
Stability only considers the linearized equation, because it analyses the local behaviour. \\
In the case of this equation, we can express $u^{n+1}$ as a function of $u^n$:
\begin{equation}
	u^{n+1} = \rho u^n 
\end{equation}
where $\rho = \sum_{i=1}^m \frac{(\lambda \Delta t)^m}{m!}$ for a Runge-Kutta scheme of order $m$. \\
The method is stable if $|\rho|\le 1$. 
\begin{itemize}
	\item [$\to$] Note: the intersection of the marginal stability curve ($|\rho|=1$) with the imaginary axis is particularly relevant, as it is necessary to determine the maximum value of the CFL for simple spatial-integration schemes such as Euler explicit, because the $\lambda$ values of those schemes are purely imaginary. In short, the stability region of the spatial scheme must be inside the stability region of the stability region of the time scheme to be fully stable. 
\end{itemize}
\begin{figure}[H]
	\centering
	\includegraphics[width=.5\textwidth]{img/rk.png}
	\caption{Stability regions of Runge-Kutta schemes.}
	\label{fig:rk-stability}
\end{figure}
\subsection{General Explicit Runge-Kutta schemes}
A Butcher tableau is a representation of the RK coefficients meant for them to be easy to read.\\
\begin{center}
	\begin{tabular}{|c|ccc|c|}
		\hline 
		& & & & $\gamma_1$\\
		$\alpha_2$ & $\beta_{21}$ & & & $\gamma_2$\\
		$\alpha_3$ & $\beta_{31}$ & $\beta_{32}$ & & $\gamma_3$\\
		$\alpha_4$ & $\beta_{41}$ & $\beta_{42}$ & $\beta_{43}$ & $\gamma_4$ \\ \hline  
	\end{tabular}\\
\end{center}
The first column contains the time weights, the $\beta$ are the space weights, and the $\gamma$ are the weights in the linear combination of $k_i$. \\
We can check that we always have $\alpha_i = \sum_{j}\beta_{ji}$ and that $\sum_{i}\gamma_i = 1$. 
\begin{itemize}
	\item [$\to$] Note: the diagonal schemes mentioned earlier give a diagonal matrix for the parameters $\beta$.
\end{itemize}

In an Explicit Runge-Kutta scheme (ERK), the number of substeps (number of coefficients $k$) is not necessarily the order of the scheme: it is possible to do ERK54, which has 5 substeps, but only an order 4. This is because the expression of the amplification paramater $\rho$ changes, and does not correspond exactly to the Taylor development terms. 
\begin{figure}[H]
	\centering 
	\includegraphics[width=.5\textwidth]{img/rk54.png}
	\caption{Stability regions for Explicit Runge-Kutta schemes.}
	\label{fig:rk54}
\end{figure}
You can see on \ref{fig:rk54} that the scheme RK54 goes to the right on the imaginary axis. This is a bad behaviour for stability, as there is a small physically stable zone that is not numerically stable. 
\subsection{RK4 pseudocode}
\begin{algorithm}[H]
	\caption{RK4 pseudocode}
	\begin{algorithmic}[1]
		\State $(t,u)$ = time $t^n$ and solution $u(t^n)=u^n$;
		\State Save to avoid overwriting: $u_{safe} = u$, $t_{safe} = t$;
		\For {$k=1,2,3,4$}
		\State $u_{\ell} = u_{safe} + \alpha_k \Delta u$
		\State $t_{\ell} = t_{safe} + \alpha_k \Delta t$
		\State Evaluate: $\Delta u = \Delta t f(u_{\ell}, t_\ell)$
		\State And update: $\begin{cases}
			u = u + \gamma_k \Delta u \\
			t = t + \gamma_k \Delta t
		\end{cases}$
		\EndFor\\
		\Return $(t,u)$
	\end{algorithmic}
\end{algorithm}
At the end of the loop, $(t,u)$ are the time $t^{n+1} = t^n + \Delta t$ and the solution $u(t^{n+1}) = u^{n+1}$. This algorithm needs 4 arrays to be stored. For big simulations, this is a lot of data, and this is why there exists some low-storage RK methods that only require 3 arrays. They use different paramater values, e.g. for RK3:\\
\begin{center}
	\begin{tabular}{|c|cc|c|}
		\hline 
		& & & 5/30\\
		1/3 & 1/3 & & 9/30\\
		3/4 & -3/16 & 15/16 & 16/30\\ \hline 
	\end{tabular}
\end{center}
\section{Multistep time schemes}
Multisteps time schemes use more than one previous step to compute the value $t^{n}$. They are generally cheap, but not self starting: $t^1$ cannot be computed through it, as it would need to know $t^{-1}$. Moreover, they produce multiple solutions even though only one is physically correct. 
\subsection{Leap-frog}
The scheme is 
\begin{equation}
	\frac{u^{n+1}-u^{n-1}}{2\Delta t} = f(u^n, t^n)\Longleftrightarrow u^{n+1} = u^{n-1} + 2\Delta t f(u^n, t^n)
\end{equation}
The scheme is centered around $t^n$, meaning it is of order 2.\\
To analyse its stability region, we have 
\begin{equation}
	\frac{du}{dt} = \lambda u \Longrightarrow \begin{cases}
		u^n = \rho u^{n-1}\\u^{n+1} = \rho^2 u^{n-1}
	\end{cases}
\end{equation}
Then, 
\begin{equation}
	\rho^2 = 1+2\lambda \Delta t \rho \Longleftrightarrow \begin{cases}
		\rho_1 + \rho_2 = 2\lambda \Delta t \\
		\rho_1 \rho_2 = -1 
	\end{cases}\Longrightarrow \rho = \lambda \Delta t \pm \sqrt{1+(\lambda \Delta t)^2}
\end{equation}
By Taylor series, 
\begin{equation}
	\begin{cases}
		\rho_1 = 1+\lambda \Delta t + \frac{(\lambda \Delta t)^2}{2} - \frac{(\lambda \Delta t)^4}{8} + \dots \approx e^{\lambda \Delta t}\\
		\rho_2 = -1+\lambda \Delta t - \frac{(\lambda \Delta t)^2}{2} + \frac{(\lambda \Delta t)^4}{8} + \dots \approx e^{-\lambda \Delta t}\\
	\end{cases}
\end{equation}
$\rho_1$ is the physical root and $\rho_2$ is called the parasitic root. Because of the condition $\rho_1\rho_2=-1$ and the stability condition $|\rho_1|,|\rho_2|\le 1$, we need $|\rho_1| = |\rho_2| = 1$.\\

Then, the solution of the scheme is 
\begin{equation}
	\rho = c_1\rho_1 + c_2\rho_2 \Longrightarrow u^n = (c_1\rho_1 + c_2\rho_2)u^{n-1}
\end{equation}
where $u^1$ must be computed using another scheme with less steps, e.g. RK2. 
\chapter{Fourier document}
\textcolor{red}{TODO.}
\end{document}