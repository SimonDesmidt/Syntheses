\documentclass[12pt, openany]{report}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{amssymb}
\usepackage{multicol}
\usepackage[a4paper,left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm]{geometry}
\usepackage[english]{babel}
\usepackage{libertine}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{float}
\usepackage{enumitem}
\usepackage{pythonhighlight}
\usepackage[]{titletoc}
\usepackage{empheq}
\usepackage{titlesec}
\usepackage{mathpazo}
\usepackage{xfrac}
\usepackage{textcomp}
\usepackage{mathtools}
\usepackage{caption}
\usepackage{tabularray}
\usepackage{subcaption}
\usepackage[bottom]{footmisc}
\usepackage{pdfpages}
\usepackage{tabularx}
\usepackage{amsthm}
\usepackage[skins]{tcolorbox}
\titleformat{\chapter}[display]
  {\normalfont\bfseries}{}{0pt}{\Huge}
\usepackage{hyperref}
\newcommand{\hsp}{\hspace{20pt}}
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\renewcommand{\P}{\mathbb{P}}
\newcommand{\A}{\mathcal{A}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\E}{\mathbb{E}}
\theoremstyle{definition}
\newtheorem{thm}{Theorem}[chapter]
\newtheorem{definition}[thm]{Definition}
\newtheorem{lem}[thm]{Lemma}

\hbadness=100000
\begin{document}
\begin{titlepage}
    \begin{sffamily}
    \begin{center}
        \includegraphics[scale=0.25]{img/page_de_garde.png} \\[1cm]
        \HRule \\[0.4cm]
        { \huge \bfseries LINMA2491 Operational Research \\[0.4cm] }
    
        \HRule \\[1.5cm]
        \textsc{\LARGE Simon Desmidt\\ Issambre L'Hermite Dumont}\\[1cm]
        \vfill
        \vspace{2cm}
        {\large Academic year 2024-2025 - Q2}
        \vspace{0.4cm}
         
        \includegraphics[width=0.15\textwidth]{img/epl.png}
        
        UCLouvain\\
    
    \end{center}
    \end{sffamily}
\end{titlepage}

\setcounter{tocdepth}{1}
\tableofcontents
\chapter{Definition and notation}
\begin{itemize}
	\item Given $\Omega$, a sigma-algebra $\A$ is a set of subsets of $\Omega$, with the elements called events, such that:
	\begin{itemize}
		\item $\Omega \in \A$
		\item if $A \in \A$ then also $\Omega - A \in \A$
		\item if $A_i \in \A$ for $i = 1,2, \dots$ then also $\cup_{i=1}^\infty A_i \in \A$
		\item if $A_i \in \A$ for $i = 1,2, \dots$ then also $\cap_{i=1}^\infty A_i \in \A$
	\end{itemize}
	\item Consider: 
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.25]{img/space.jpg} 
	\end{figure}
	\begin{itemize}
		\item The state space is the set of all values of the system at each stage. 
		\begin{equation}
			S_0 = \{C\},\qquad S_1 = \{C_u, C_d\},\qquad S_2 = \{C_{uu}, C_{ud}, C_{dd}\}
		\end{equation}
		\item  The sample space is the set of all possible combination of the system.
		\begin{equation}
			\Omega = S_0 \times S_1 \times S_2 = \{(C, C_u, C_{uu}), (C, C_u, C_{ud}), (C, C_u, C_{dd}), \dots\}
		\end{equation}
	\end{itemize}
	\item The power set of $\Omega$ is the set of all of the subsets, denoted $\mathcal{B}(\Omega)$.
	\item The probability space is the triplet $(\Omega, \A, P)$ where $P$ is a probability measure.
	\begin{itemize}
		\item $P(\emptyset) = 0$
		\item $P(\Omega) = 1$
		\item $P(\cup_{i=1}^\infty A_i) = \sum_i P(A_i)$ if $A_i$ are disjoint
	\end{itemize} 
	\item $\forall t, A_t$ is the set of events on which we have information at stage $t$. For example, $A_0 = \{C\}$, $A_1 = \{C, C_u, C_d\}$. Thus is it evident that $ t_1 \leq t_2 \Rightarrow \A_{t_1} \subseteq \A_{t_2}$
	\item Consider the following problem with $x \in \R^n$ and domain $\mathcal{D}$:
	\begin{equation}
		\begin{aligned}
			&\min f_0(x), \qquad s.t.\\
			&f_i(x) \leq 0, i = 1, \dots, m\\
			&h_j(x) = 0, j = 1, \dots, p
		\end{aligned}
	\end{equation}
	Then the Lagrangian function is defined as $L: \R^n \times \R^m \times \R^p \to \R$:
	\begin{equation}
		L(x, \lambda, \nu) = f_0(x) + \sum_{i=1}^m \lambda_i f_i(x) + \sum_{j=1}^p \nu_j h_j(x)
	\end{equation}
	\item  The Lagrange dual function is defined as $g: \R^m \times \R^p \to \R$:
	\begin{equation}
		g(\lambda, \nu) = \inf_{x \in \mathcal{D}} L(x, \lambda, \nu)
	\end{equation}
	\item The Lagrange dual problem is a lower bound on the optimal value of the primal problem
	\item Lagrange relaxation of Stochastic Programs, consider the two problems:
	\begin{equation}
		\begin{aligned}
			\min f_1(x) + \E_\omega[f_2(y(\omega), \omega)] \qquad & \qquad \min f_1(x) + \E_\omega[f_2(y(\omega), \omega)]\\
			s.t \qquad h_{1i}(x) \leq 0, i = 1, \dots, m_1 \qquad & \qquad s.t. \qquad h_{1i}(x) \leq 0, i = 1, \dots, m_1\\
			h_{2i}(x,y(\omega),\omega) \leq 0, i = 1, \dots, m_2 \qquad & \qquad h_{2i}(x(\omega),y(\omega),\omega) \leq 0, i = 1, \dots, m_2\\
			& \textcolor{red}{\qquad x(\omega) = x} 
		\end{aligned}
	\end{equation}
	The red constraint is the non-anticipativity constraint, it transforms the deterministic variable into a stochastic variable. \textcolor{red}{A VERIFIER}
	\item The dual of a stochastic program is:
	\begin{equation}
		\begin{aligned}
			& g(\nu) = g1(\nu) + \E_\omega(g2(\nu, \omega))\\
			where \qquad &  \\
			& g_1(\nu) = \inf f_1(x) + \left( \displaystyle \sum_{\omega \in \Omega} \nu(\omega) \right)^T x\\
			& s.t. \quad h_{1i} (x) \leq 0, i = 1, \dots, m_1\\
			and \qquad &  \\
			& g_2(\nu, \omega) = \inf f_2(y(\omega) \omega) - \nu x(\omega)\\
			& s.t. \quad h_{2i}(x(\omega), y(\omega), \omega) \leq 0, i = 1, \dots, m_2
		\end{aligned}
	\end{equation}
	\item  With $p^*$ the solution of the primal problem and $d^*$ the solution of the dual problem, we have:
	\begin{itemize}
		\item Weak duality: $d^* \leq p^*$
		\item Strong duality: $d^* = p^*$
	\end{itemize}
	\item The KKT conditions are necessary and sufficient for optimality in convex optimization, there aren't unique. They are:
	\begin{itemize}
		\item Primal constraint: $f_i(x) \leq 0, i = 1, \dots, m$, $h_j(x) = 0, j = 1, \dots, p$
		\item Dual constraint: $\lambda \geq 0$
		\item Complemetarity slackness: $\lambda_i f_i(x) = 0, i = 1, \dots, m$
		\item Gradient of the Lagrangian: $\nabla_x L(x, \lambda, \nu) = 0$
	\end{itemize}
	\item An extreme point of a polyhedron $P$ is a point $x\in P$ such that it cannot be expressed as a linear combination of two distinct points in $P$, i.e. an extreme point is a vertex of the polyhedron.
	\item An extreme ray of a polyhedron $P$ is $\sigma\in \R^n$ such that for all $x\in P$, for all $\lambda \in [0,1]$, 
	\begin{equation}\label{eq:extreme}
		(x+\lambda \sigma)\in P
	\end{equation}
	i.e. it is a direction in which we can travel infinitely without leaving the polyhedron. 
\end{itemize}
\section{Reminders on subgradients}
$\pi$ is a subgradient of the function $g$ at $u$ if 
\begin{equation}
	g(w)\ge g(u)+ \pi^T(w-u)\qquad \forall w
\end{equation}
If $g=\max \{g_1,g_2\}$ with $g_{1,2}$ convex and differentiable, the subgradient of $g$ at $u_0$ is 
\begin{itemize}
	\item $\pi=\nabla g_1(u_0)$ if $g_1(u_0)>g_2(u_0)$
	\item $\pi=\nabla g_2(u_0)$ if $g_2(u_0)>g_1(u_0)$
	\item The line segment $[\nabla g_1(u_0),\nabla g_2(u_0)]$ if $g_1(u_0)=g_2(u_0)$
\end{itemize}
The subdifferential of $g$ at $u$ is the set of all subgradients of $g$ at $u$, denoted $\partial g(u)$. If $g$ is convex, then its subdifferential is nonempty on its domain, and $g$ is differentiable at $u$ if its $\partial g(u) = \{\pi\}$. 
\subsection{Use in duality}
Define $c(u)$ as the optimal value of 
\begin{equation}
	\begin{aligned}
		c(u)&=\min f_0(x)\\
		f_i(x) &\le u_i \qquad i=1,\dots,m\\
	\end{aligned}
\end{equation}
where $x\in dom f_0$ and $f_0,f_i$ are convex functions.
\begin{itemize}
	\item $c(u)$ is convex;
	\item If strong duality holds, denote $\lambda^\star$ as the maximizer of the dual function 
	\begin{equation}
		\inf_{x\in dom f_0} (f_0(x) - \lambda^T(f(x)-u))
	\end{equation}
	for $\lambda \le 0$. Then, $\lambda^\star \in \partial c(u)$. $\lambda_i$ represents the sensitivity of $c(u)$ to a marginal change in the right-hand side of the $i$-th constraint. 
\end{itemize}
\chapter{Modelling}
\section{Introduction}
\begin{itemize}
	\item  For a certain sequence of events $x \to \omega \to y(\omega)$, where $\omega$ is the uncertainty,
	\begin{itemize}
		\item A first-stage decision is a decision that is made before the uncertainty is revealed (i.e. in $x$);
		\item A second-stage decision is a decision that is made after the uncertainty is revealed (i.e. in $y(\omega)$).
	\end{itemize}
	\item We can have the following mathematical formulation:
	\begin{equation}\label{eq:TSSLP_formulation}
		\begin{aligned}
			\min c^T x &+ \E[\min q(\omega)^T y(\omega)]\\
			Ax &= b\\
			T(\omega) x &+ W(\omega)y(\omega) = h(\omega)\\
			x \geq 0&, y(\omega) \geq 0
		\end{aligned}
	\end{equation}
	\begin{itemize}
		\item First-stage decision variable: $x \in \R^{n_1}$
		\item First-stage parameter: $c \in \R^{n_1}$, $b \in \R^{m_1}$ and $A \in \R^{m_1 \times n_1}$
		\item Second-stage decision: $y(\omega) \in \R^{n_2}$
		\item Second-stage data: $q(\omega) \in \R^{n_2}$, $h(\omega) \in \R^{m_2}$ and $T(\omega) \in \R^{m_2 \times n_1}$, $W(\omega) \in \R^{m_2 \times n_2}$
	\end{itemize}
\end{itemize}
\section{Representations}
\subsection{Scenario Trees}
A scenario tree is a graphical representation of a Markov process $\{\xi_t\}_{t\in \Z}$, where the nodes are the history of realizations ($\xi_{[t]}=(\xi_1,\dots,\xi_t)$), and the edges are the transitions from $\xi_{[t]}$ to $\xi_{[t+1]}$.
\begin{itemize}
	\item We denote the root as $t=1$;
	\item An ancestor of a node $\xi_{[t]}$, $A(\xi_{[t]})$ is a unique adjacent node which precedes $\xi_t$;
	\item The children of a node, $C(\xi_{[t]})$ are the nodes that are adjacent to $\xi_{[t]}$ and occur at stage $t+1$.
\end{itemize}
\begin{figure}[H]
	\centering 
	\includegraphics[width = .3\textwidth]{img/tree.png}
\end{figure}
\subsection{Lattice}
A lattice is a graphical representation of a Markov process $\{\xi_t\}_{t\in \Z}$, where the nodes are the realizations $\xi_t$ and the edges correspond to the transitions from $\xi_t$ to $\xi_{t+1}$. 
\begin{figure}[H]
	\centering 
	\includegraphics[width = .3\textwidth]{img/lattice.png}
\end{figure}
\subsection{Serial Independence}
A process satisfies serial independence if, for every stage $t$, $\xi_t$ has a probability distribution that does not depend on the history of the process. Thus, the probability measure is 
\begin{equation}
	\P\left[\xi_t(\omega)=i\left|\xi_{[t-1]}(\omega)\right.\right] = p_t(i) \qquad \forall \ \xi_{[t-1]}\in\Xi_{[t-1]}, i\in\Xi_t
\end{equation}
\section{Multi Stage Stochastic Linear Program}
\subsection{Notation}
\begin{itemize}
	\item Probability space: $(\Omega, 2^\Omega, \P)$ with filtration $\{\A\}_{t\in \{1, \dots, H\}}$
	\item $c_t(\omega) \in \R^{n_t}$: cost coefficients
	\item $h_t(\omega) \in \R^{m_t}$: right-hand side parameters
	\item $W_t(\omega) \in \R^{m_t \times n_t}$: coefficients of $x_t(\omega)$
	\item $T_{t-1}(\omega) \in \R^{m_t \times n_{t-1}}$: coefficients of $x_{t-1}(\omega)$
	\item $x_t(\omega)$: set of state and action variables in period $t$
	\item We implicitly enforce non-anticipativity by requiring that $x_t$ and $\xi_t$ are adapted to filtration $\{\mathcal{A}\}_{t\in \{1, \dots, H\}}$ 
	\item $\forall A \in \mathcal{A}_k \setminus \mathcal{A}_{k-1}, \: x_t(\omega_1)=x_t(\omega_2) \: \forall\omega_1,\omega_2 \in A$
\end{itemize}
\subsection{General formulation of the MSLP}
The extended formulation of the MSLP is: 
\begin{equation}
	\begin{aligned}
		&\min c_1^Tx_1 + \E[c_2(\omega)^T x_2(\omega)+ \dots + c_H(\omega)^Tx_H(\omega)]\\
		&s.t. \quad W_1x_1 = h_1\\
		&T_1(\omega)x_1 + W_2(\omega)x_2(\omega) = h_2(\omega), \omega \in \Omega\\
		&\qquad \qquad \vdots\\
		&T_{t-1}(\omega)x_{t-1}(\omega) + W_t(\omega)x_t(\omega) = h_t(\omega), \omega \in \Omega\\
		&\qquad \qquad \vdots\\
		&T_{H-1}(\omega)x_{H-1}(\omega) + W_H(\omega)x_H(\omega) = h_H(\omega), \omega \in \Omega\\
		&x_1 \geq 0, x_t(\omega) \geq 0, t=2, \dots, H
	\end{aligned}
\end{equation}
We can now consider two specific instantiations of the MSLP: the scenario tree (MSLP-ST) and the lattice (MSLP-L). Using these notations:
\begin{itemize}
	\item $\omega_t \in S_t$ : index in the support $\Xi_t$ of random input $\xi_t$
	\item $\omega_{[t]} \in S_1 \times \dots \times S_t$ (interpretation: index in $\Xi_{[t]} = \Xi_1 \times \dots \times \Xi_t$, which is the history of realizations, up to period $t$)
\end{itemize}
\subsection{Scenario Tree formulation}
\begin{equation}
	 \begin{aligned}
		&\min c_1^Tx_1 + \E\left[c_2(\omega_{[2]})^T x_2(\omega_{[2]})+ \dots + c_H(\omega_{[H]})^Tx_H(\omega_{[H]})\right]\\
		&s.t. \quad W_1x_1 = h_1\\
		&T_1(\omega_{[2]})x_1 + W_2(\omega_{[2]})x_2(\omega_{[2]}) = h_2(\omega_{[2]}), \omega_{[2]} \in S_1 \times S_2\\
		&\qquad \qquad \vdots\\
		&T_{t-1}(\omega_{[t]})x_{t-1}(\omega_{[t-1]}) + W_t(\omega_{[t]})x_t(\omega_{[t]}) = h_t(\omega_{[t]}), \omega_{[t]} \in S_1 \times \dots \times S_t\\
		&\qquad \qquad \vdots\\
		&T_{H-1}(\omega_{[H]})x_{H-1}(\omega_{[H-1]}) + W_H(\omega_{[H]})x_H(\omega_{[H]}) = h_H(\omega_{[H]}), \omega_{[H]} \in S_1 \times \dots \times S_H\\
		&x_1 \geq 0, x_t(\omega_{[t]}) \geq 0, t=2, \dots, H
	 \end{aligned}
\end{equation}
\subsection{Lattice formulation}
\begin{equation}
	\begin{aligned}
		&\min c_1^Tx_1 + \E\left[c_2(\omega_{2})^T x_2(\omega_{[2]})+ \dots + c_H(\omega_{H})^Tx_H(\omega_{[H]})\right]\\
		&s.t. \quad W_1x_1 = h_1\\
		&T_1(\omega_{2})x_1 + W_2(\omega_{2})x_2(\omega_{[2]}) = h_2(\omega_{2}), \omega_{[2]} \in S_1 \times S_2\\
		&\qquad \qquad \vdots\\
		&T_{t-1}(\omega_{t})x_{t-1}(\omega_{[t-1]}) + W_t(\omega_{t})x_t(\omega_{[t]}) = h_t(\omega_{t}), \omega_{[t]} \in S_1 \times \dots \times S_t\\
		&\qquad \qquad \vdots\\ 
		&T_{H-1}(\omega_{H})x_{H-1}(\omega_{[H-1]}) + W_H(\omega_{H})x_H(\omega_{[H]}) = h_H(\omega_{H}), \omega_{[H]} \in S_1 \times \dots \times S_H\\
		&x_1 \geq 0, x_t(\omega_{[t]}) \geq 0, t=2, \dots, H
	\end{aligned}
\end{equation}
\begin{itemize}
	\item [$\rightarrow$] Note: There exists some relations to other decision making problems such as statistical decision theory, dynamic programming, online optimization and stochastic control.
\end{itemize}

\chapter{Performance}
\section{Notations}
Using \eqref{eq:TSSLP_formulation}, let's define the following:
\begin{itemize}
	\item $z(x,\xi) = c^Tx+Q(x,\xi)+\delta(x|K_1)$
	\item $Q(x,\xi) = \displaystyle \min_y\{q(\omega)^Ty\ |\ W(\omega)y=h(\omega)-T(\omega)x\}$
	\item $K_1 = \{x|Ax=b,x\geq0\}$ is the set of feasible first-stage decisions
	\item $K_2(\omega)=\{x\ |\ \exists y\geq0:W(\omega)y=h(\omega)-T(\omega)x\}$ is the set of first-stage decisions that have a feasible reaction in the second stage for $\omega \in \Omega$
	\item It is possible that $z(x,\xi) = + \infty$ (if $x \notin K_1 \cap K_2(\omega)$)
	\item It is possible that $z(x,\xi) = - \infty$ (unbounded below)
\end{itemize}
\section{Expected value of perfect information}
There are 2 tactics:
\begin{itemize}
	\item \textbf{wait-and-see} value is the expected value of reacting with perfect foresight (we know everything that will happen) $x^*(\xi)$ to $\xi$: 
	\begin{equation}
		WS = \E[\displaystyle \min_x z(x,\xi)] = \E[z(x^*(\xi),\xi)]
	\end{equation}
	\item \textbf{here-and-now} value is the expected value of the recourse problem (remove non-anticipativity constraint):
	\begin{equation}
		SP = \displaystyle \min_x \E[z(x,\xi)]
	\end{equation}
\end{itemize}
The \textbf{expected value of perfect information} is like the value we give to getting a perfect forecast for the future and is thus defined like this:
\begin{equation}
	EVPI = SP - WS
\end{equation}
\section{The value of the stochastic solution}
Here too there are 2 tactics:
\begin{itemize}
	\item \textbf{expected value problem}
	\begin{equation}
		EV = \displaystyle \min_x z(x,\bar{\xi}) = \E[\xi]
	\end{equation}
	and its \textbf{expected value solution} is noted $x^*(\bar{\xi})$.
	\item \textbf{expected value of using the EV solution} measures the performance of $x^*(\bar{\xi})$:
	\begin{equation}
		EEV = \E[z(x^*(\bar{\xi}),\xi)]
	\end{equation}
\end{itemize}
% We also have $EEV \geq SP$.\\
The \textbf{value of the stochastic solution} is noted like this:
\begin{equation}
	VSS = EEV - SP
\end{equation}
\section{Basic inequalities}
\subsection{Crystal Ball}
For every $\xi$, we have $z(x^*(\xi),\xi) \leq z(x^*,\xi)$ where $x^*$ is the optimal solution to the stochastic program. And if we take the expectation of this inequality, we have $WS \leq SP$, because $WS$ is a relaxation. It explains that we can do better with a crystal ball. 
\subsection{Lazy solution}
Knowing that $x^*$ is the optimal solution of $\displaystyle \min_x \E[z(x,\xi)]$ and $x^*(\bar{\xi})$ is a solution but not necessarily optimal then we have $SP \leq EEV$, because:
\begin{equation}
	\displaystyle \min_x \E[z(x,\xi)] = SP \leq EEV = \E[z(x^*(\bar{\xi}),\xi)]
\end{equation}
\subsection{Link between all the values}
We know that:\\
\begin{minipage}{.5\textwidth}
	\begin{itemize}
		\item $VSS \geq 0$
		\item $EVPI \geq 0$
		\item $VSS \leq EEV - EV$
	\end{itemize}
\end{minipage}
\begin{minipage}{.5\textwidth}
	\begin{itemize}
		\item $EVPI \leq EEV -EV$
		\item If $EEV - EV = 0$ then $VSS = EVPI = 0$
	\end{itemize}
\end{minipage}
and the inequalities can be summarized in the following diagram:
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.5]{img/link_ineq.png}
\end{figure}
\section{Bounds on EVPI and VSS}
First let's introduce the pairs subproblem of $\xi^r$ and $\xi^k$:
\begin{equation}
	\begin{aligned}
		\min \: &z^P (x, \xi^r,\xi^k) = c^Tx + p^rq^Ty(\xi^r) + (1-p^r)q^Ty(\xi^k)\\
		s.t. \: &Ax = b\\
		&Wy(\xi^r) = \xi^r-Tx\\
		&Wy(\xi^k) = \xi^k-Tx\\
		&x,y\geq0
	\end{aligned}
\end{equation}
\begin{itemize}
	\item $(\bar{x}^k , \bar{y}^k , y(\xi^r ))$ denotes an optimal solution to the problem and $z^k$ is the optimal objective function value $z^P (\bar{x}^k , \bar{y}^k , y(\xi^k ))$
	\item $z^P (x, \xi^r , \xi^r)$ corresponds to the deterministic optimization against the
	reference scenario
	\item if $\xi^r \notin \Xi$, $p^r = 0$ and $z^P (x, \xi^r , \xi^k ) = z(x, \xi^k )$
\end{itemize}
The \textbf{sum of pairs expected value (SPEV)}:
\begin{equation}
	SPEV = \frac{1}{1-p^r} \sum_{k=1,k \neq r}^{K} p^k \min z^P(x, \xi^r,\xi^k)
\end{equation}
When $\xi^r \notin \Xi$ then $SPEV = WS$: When $p^r = 0, z^P(x,\xi^r,\xi^k)$ coincides with $z(x,\xi^k)$. Therefore $SPEV = \sum_{k=1}^{K} p^k \min_x z(x,\xi^k) = WS$.\\
We then know $WS \leq SPEV \leq SP$.
\subsection{Upper bound on SP: EVRS and EPEV}
\begin{itemize}
	\item The \textbf{expected value of the reference scenario} is $EVRS =  \E_\xi(\bar{x}^r,\xi)$, where $\bar{x}^r$ is the optimal solution to $z(x,\xi^r)$.
	\item The \textbf{expectation of pairs of expected value} is defined as \[EPEV = \min_{k=1,\dots,K\cup\{r\}}\E_\xi(\bar{x}^r,\xi)\] where $(\bar{x}^k,\bar{y}^k, y(\xi^K))$ is the optimal solution to the pairs subproblem of $\xi^r$ and $\xi^k$.
\end{itemize}
As $SP,EPEV,EVRS$ are the optimal values of $\min_x \E_\xi z(x,\xi)$ over smaller feasible sets:
\begin{equation}
	SP \leq EPEV \leq EVRS
\end{equation}
Because
\begin{itemize}
	\item $SP$: $x \in K_1 \cap K_2$
	\item $EPEV$: $x \in K_1 \cap K_2 \cap \{\bar{x}^k,k=1,\dots,K\cup\{r\}\}$
	\item $EVRS$: $x \in \bar{x}^r \cap K_1 \cap K_2$
\end{itemize}
\section{Estimations of WS and EEV}
An estimation of WS and EEv can be done through a sample mean approximation: from samples $\xi_i = \xi(\omega_i)$ for $i=1,\dots,K$, 
\begin{enumerate}
	\item Compute $x^\star (\bar \xi)$;
	\item Compute $WS_i = z(x^\star (\xi_i), \xi_i)$ and $EEV_i = c^Tx^\star (\xi_i) + Q(x^\star (\bar \xi), \xi_i)$;
	\item Estimate $\Bar{WS} = \frac{1}{K}\sum_{i=1}^K WS_i$ and $\bar{EEV} = \frac{1}{K}\sum_{i=1}^K EEV_i$.  
\end{enumerate}
\subsection{Central Limit Theorem}
Suppose $\{X_1, \dots, X_K\}$ is a sequence of iid rv with $\E[X_i]=\mu$ and $Var[X_i] = \sigma^2<\infty$. Then, as $n$ approaches infinity, $\sqrt{n}(S_n-\mu)$ converge in distribution to a normal $\mathcal{N}(0,\sigma^2)$:
\begin{equation}
	\sqrt{n}\left(\left(\frac{1}{n}\sum_{i=1}^n X_i\right)-\mu\right) \xrightarrow{d} \mathcal{N}(0,\sigma^2)
\end{equation}
The central limit theorem is useful to decrease the importance of rare but extreme events. 
\subsection{Importance sampling}
Suppose we wish to estimate $\E[C(\omega)]$, where $\omega$ is distributed according to $f(\omega)$ and estimates $\E[C(\omega)]$ with $\displaystyle \sum_{i=1}^N \frac{1}{N}C(\omega_i)$. A sample average pulls samples $\omega_i$ according to the distribution function $f(\omega)$, while the importance sampling pulls the samples $\omega_i$ according to the distribution $\displaystyle g(\omega) = \frac{f(\omega)C(\omega)}{\E[C(\omega)]}$, where the $\E[C(\omega)]$ is an approximation of the real expectation. It then estimates $\E[C(\omega)]$ with $\displaystyle \sum_{i=1}^N \frac{1}{N}\frac{f(\omega_i)C(\omega_i)}{g(\omega_i)}$. 
\chapter{Benders Decomposition}
\section{Cutting plane methods}
A cutting plane method is an optimisation method based on the idea of iteratively refining the objective function, or a set of feasible constraints of a problem through linear inequalities (see LINMA2450). 
\subsection{Nomenclature}
\begin{itemize}
	\item The benders decomposition is a specific method for obtaining the cutting planes when $F(x)$ is the value function of a second-stage linear program. 
	\item The L-shaped method is a specific instance of Benders decomposition when the second-stage linear program is decomposable into a set of scenarios.
	\item The multi-cut L-shaped method is an alternative to the L-shaped method which generates multiple cutting planes at step 1 of Kelley's method (see \ref{sec:Kelley}). 
\end{itemize}
\subsection{Kelley's Cutting Plane Algorithm}\label{sec:Kelley}
This algorithm is designed to solve convex but non-differentiable optimization problems of the form
\begin{equation}
	\begin{aligned}
		z^\star &= \min c^Tx + F(x)\\
		\text{s.t. }& x\in X\\
	\end{aligned}
\end{equation}
where $X\subseteq \R^n$ is convex and compact, $F:\R^n\to \R$ is convex and $c\in \R^n$ is a parameter vector. \\
Let us define 
\begin{itemize}
	\item $L_k:\R^n\to \R$ a lower bound function of $F(x)$ at iteration $k$;
	\item A lower bound $L_k$ of $z^\star$ at iteration $k$;
	\item An upper bound $U_k$ of $z^\star$ at iteration $k$.
\end{itemize}
\begin{algorithm}
    \caption{Kelley's Cutting plane algorithm}\label{algo:Kelley}
    \begin{algorithmic}[1]
    \State \textbf{Step 0:} Set $k=0$ and assume $x_1\in X$ is given. Set $L_0(x)=-\infty$ for all $x\in X$, $U_0 = c^Tx_1 + F(x_1)$, and $L_0 = -\infty$.
	\State \textbf{Step 1:} Set $k=k+1$. Find $a_k\in \R$ and $b_k\in \R^n$ such that \[F(x_k)=a_k+b_k^Tx_k\] \[F(x)\ge a_k + b_k^Tx\qquad x\in X\]
	\State \textbf{Step 2:} Set \[U_k = \min(U_{k-1},c^Tx_k + F(x_k))\] and \[L_k(x) = \max(L_{k-1}(x),a_k+b_k^Tx) \qquad x\in X\]
	\State \textbf{Step 3:} Compute \[L_k = \min_{x\in X} L_k(x) + c^Tx\] and denote $x_{k+1}$ as the optimal solution of this problem.
	\State \textbf{Step 4:} If $U_k - L_k =0$, stop. Otherwise, go to step 1.
    \end{algorithmic}
\end{algorithm}
\section{Context and description}
Consider the following optimization problem:
\begin{equation}
	\begin{aligned}
		z^\star &= \min c^Tx + q^Ty\\
		Ax&=b\\
		Tx + Wy&=h\\
		x, y\geq0\\
	\end{aligned}
\end{equation}
with $x\in \R^{n_1}$, $y\in \R^{n_2}$, $c\in \R^{n_1}$, $q\in \R^{n_2}$, $A\in \R^{m_1\times n_1}$, $b\in \R^{m_1}$, $T\in \R^{m_2\times n_1}$, $W\in \R^{m_2\times n_2}$, $h\in \R^{m_2}$\footnote{It is not necessarily a stochastic problem}.\\
We use Benders decomposition when the entire problem is difficult to solve, and if the constraint $Tx+Wy=h$ is ignored, the problem becomes easy to solve, or if fixing $x$ simplifies the computation of the solution. 
\subsection{Idea of Benders decomposition}
Define the value function $V:\R^{n_1}\to \R$:
\begin{equation}\label{eq:benders}
	\begin{aligned}
		V(x) &= \min_y\{q^Ty\}\\
		Wy&=h-Tx\\
		y\geq0
	\end{aligned}
\end{equation}
Or equivalently,
\begin{equation}
	\begin{aligned}
		\min \ &c^Tx+V(x)\\
		Ax&=b\\
		x&\in dom(V)\\
		x&\ge 0
	\end{aligned}
\end{equation}
where $dom(V) = \{x\in \R^{n_1}\ |\ \exists y\geq0:Wy=h-Tx\}$.\\
The dual of \eqref{eq:benders} is 
\begin{equation}
	\begin{aligned}
		\max_{\pi}& \pi^T(h-Tx)\\
		\pi^TW&\le q^T
	\end{aligned}
\end{equation}
Let us call $E$ the set of extreme points of $\pi^TW\le q^T$ and $R$ the set of extreme rays of $\pi^TW\le q^T$ (see \eqref{eq:extreme} for definitions). 
\begin{figure}[H]
	\centering
	\includegraphics[width=.35\textwidth]{img/extreme.png}
\end{figure}
We can see that $V(x)$ is a piecewise linear convex function of $x$ and, defining $x_0$ as the dual optimal multiplier of \eqref{eq:benders} given $x_0$, then $\pi_0^T(h-Tx_0)$ is a supporting hyperplane of $V(x)$ at $x_0$, because it belongs to the subdifferential of $V(x)$ at $h-Tx_0$.
\begin{figure}[H]
	\centering
	\includegraphics[width=.5\textwidth]{img/supporting_hyperplane.png}
\end{figure}
From this, we can also express the domain of $V$ as follows:
\begin{equation}
	dom(V) = \{x\ |\ \sigma^T(h-Tx)\le 0,\ \sigma\in R\}
\end{equation}
where $\sigma\in R$ is the set of extreme rays of $\pi^TW\le q^T$.
\end{document}